# Prompt metadata configuration
# Each key corresponds to a template file path (without .j2 extension)
# Fields:
#   temperature: LLM sampling temperature (0.0-1.0)
#   format: Expected output format (text/json/yaml)
#   reserve_tokens: Tokens to reserve for response (for dynamic max_tokens calculation)
#   top_p: Top-p sampling parameter
#   structured_output: Use structured JSON output mode (forces valid JSON, only for format: json)

# Generation prompts
generation/premise_main:
  temperature: 0.9
  format: json
  reserve_tokens: 800
  structured_output: true

generation/premise_with_taxonomy:
  temperature: 0.7
  format: json
  reserve_tokens: 500
  structured_output: true

generation/prose_generation:
  temperature: 0.8
  format: text
  reserve_tokens: 5000
  top_p: 0.9

generation/prose_iteration:
  temperature: 0.8
  format: text
  reserve_tokens: 5000
  top_p: 0.9

generation/prose_full_iteration:
  temperature: 0.8
  format: text
  reserve_tokens: 5000
  top_p: 0.9

generation/premise_iteration:
  temperature: 0.7
  format: json
  reserve_tokens: 800
  structured_output: true

generation/treatment_iteration:
  temperature: 0.7
  format: text
  reserve_tokens: 2500

generation/chapter_iteration:
  temperature: 0.7
  format: text
  reserve_tokens: 8000

generation/treatment_generation:
  temperature: 0.7
  format: yaml
  reserve_tokens: 2500

generation/chapter_foundation:
  temperature: 0.6
  format: yaml
  reserve_tokens: 2000

generation/chapter_single_shot:
  temperature: 0.7
  format: yaml
  reserve_tokens: 8000

generation/dedication_generation:
  temperature: 0.8
  format: text
  reserve_tokens: 300

# Analysis prompts
analysis/chapter_judging:
  temperature: 0.1
  format: json
  reserve_tokens: 2500  # Increased from 100 - judging requires detailed reasoning across multiple variants
  structured_output: true

analysis/genre_detection:
  temperature: 0.3
  format: json
  reserve_tokens: 100
  structured_output: true

analysis/taxonomy_extraction:
  temperature: 0.5
  format: json
  reserve_tokens: 500
  structured_output: true

analysis/unified_analysis:
  temperature: 0.3
  format: json
  reserve_tokens: 4000
  structured_output: true

analysis/treatment_deviation:
  temperature: 0.1
  format: json
  reserve_tokens: 3000
  structured_output: true

analysis/semantic_diff:
  temperature: 0.3
  format: text
  reserve_tokens: 1000

# Validation prompts
validation/treatment_fidelity:
  temperature: 0.1
  format: json
  reserve_tokens: 200
  structured_output: true

validation/iteration_fidelity:
  temperature: 0.1
  format: json
  reserve_tokens: 1000
  structured_output: true

# Iteration prompts (premise iteration only - chapter/prose iteration removed)
iteration/taxonomy_update:
  temperature: 0.4
  format: json
  reserve_tokens: 200
  structured_output: true

iteration/premise_revision:
  temperature: 0.5
  format: json
  reserve_tokens: 1200
  structured_output: true

# Editing prompts
editing/copy_edit:
  temperature: 0.3
  format: json
  reserve_tokens: 8000
  top_p: 0.9
  structured_output: true

# KDP metadata prompts
kdp/description:
  temperature: 0.7
  format: text
  reserve_tokens: 200

kdp/keywords:
  temperature: 0.7
  format: text
  reserve_tokens: 150

kdp/author_bio:
  temperature: 0.7
  format: text
  reserve_tokens: 300